{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.path import Path\n",
    "from matplotlib import patches\n",
    "import numpy as np\n",
    "from math import sqrt\n",
    "\n",
    "sc = pyspark.SparkContext.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 'SessionID'),\n",
       " (1, 'SessionDate'),\n",
       " (2, 'SessionDuration'),\n",
       " (3, 'SessionFrequency'),\n",
       " (4, 'RecordID'),\n",
       " (5, 'Timestamp'),\n",
       " (6, 'timeIntervalSince1970'),\n",
       " (7, 'GyroX'),\n",
       " (8, 'GyroY'),\n",
       " (9, 'GyroZ'),\n",
       " (10, 'AccX'),\n",
       " (11, 'AccY'),\n",
       " (12, 'AccZ'),\n",
       " (13, 'MagX'),\n",
       " (14, 'MagY'),\n",
       " (15, 'MagZ')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd = sc.textFile('subsetData.csv', use_unicode=False).cache()\n",
    "list(enumerate(rdd.first().split(',')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0,38:58.8,0:23,60,0,38:58.8,1540931939,-0.171710773,-0.44572688,-0.103311209,0.071121216,-0.13835144,-1.048599243,40.74794006,28.28944397,-76.89674377\n"
     ]
    }
   ],
   "source": [
    "rdd = rdd.filter(lambda x: not x.startswith('SessionID')) #remove header\n",
    "print (rdd.first())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0,38:58.8,0:23,60,0,38:58.8,1540931939,-0.171710773,-0.44572688,-0.103311209,0.071121216,-0.13835144,-1.048599243,40.74794006,28.28944397,-76.89674377', '0,38:58.8,0:23,60,0,38:58.9,1540931939,-0.135502702,-0.069837139,-0.062163506,0.024291992,-0.188186646,-1.009124756,40.6590271,28.46276855,-76.73902893', '0,38:58.8,0:23,60,0,38:58.9,1540931939,-0.058512579,0.157536365,-0.035130024,0.054092407,-0.153060913,-1.031112671,40.920578,28.33343506,-76.729599', '0,38:58.8,0:23,60,0,38:58.9,1540931939,0.010897655,0.135293643,-0.049095375,0.083969116,-0.136428833,-1.029907227,40.95025635,28.17259216,-76.5778656', '0,38:58.8,0:23,60,0,38:58.9,1540931939,0.02978213,0.011873171,-0.065315091,0.090942383,-0.140869141,-1.003616333,40.95025635,28.17259216,-76.5778656', '0,38:58.8,0:23,60,0,38:58.9,1540931939,-0.10691633,-0.048637844,-0.022522353,0.076782227,-0.139648438,-0.988525391,40.78399658,28.4384613,-76.57702637', '0,38:58.8,0:23,60,0,38:58.9,1540931939,-0.173546224,-0.073879817,-0.041812961,0.063354492,-0.120880127,-0.994796753,40.59783936,28.47503662,-76.66384888', '0,38:58.8,0:23,60,0,38:59.0,1540931939,-0.167951988,-0.162411281,-0.095466602,0.058990479,-0.106582642,-1.017730713,40.52622986,28.87744141,-76.7308197', '0,38:58.8,0:23,60,0,38:59.0,1540931939,-0.119432921,-0.169220984,-0.131895982,0.057373047,-0.103240967,-1.015472412,40.55020142,28.40675354,-76.66896057', '0,38:58.8,0:23,60,0,38:59.0,1540931939,-0.054374026,-0.100481068,-0.16716529,0.048522949,-0.113800049,-0.989639282,40.22747803,28.5483551,-76.60319519']\n"
     ]
    }
   ],
   "source": [
    "print rdd.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#same funtion & logic concepts as the pandas notebook\n",
    "def square(x):\n",
    "    return x**2\n",
    "\n",
    "def result(x,y,z):\n",
    "    return abs(sqrt(x + y + z))\n",
    "\n",
    "def getPositionVector(partitionId, records):\n",
    "    import csv\n",
    "    reader = csv.reader(records)\n",
    "    for row in reader:\n",
    "        if row[9] != 's':\n",
    "            (gyroX, gyroY, gyroZ) = (square(float(row[7])), square(float(row[8])), square(float(row[9])))\n",
    "            (accX, accY, accZ) = (square(float(row[10])), square(float(row[11])), square(float(row[12])))\n",
    "            (magX, magY, magZ) = (square(float(row[13])), square(float(row[14])), square(float(row[15])))\n",
    "            yield (result(gyroX, gyroY, gyroZ), result(accX, accY, accZ), result(magX, magY, magZ))\n",
    "\n",
    "positionVectors = rdd.mapPartitionsWithIndex(getPositionVector)\n",
    "                    \n",
    "                                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def sum_partitions(iterator):\n",
    "#    parts = np.array(list(iterator))\n",
    "#    yield np.sum(parts, 0)\n",
    "\n",
    "#positionVectors.mapPartitions(sum_partitions).collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.626323437859389, 33.13902414280171, 3006.3054821527594]\n"
     ]
    }
   ],
   "source": [
    "#get the sum of each column\n",
    "#returns (sum of gyro vectors, sum of acc vectors, sum of mag vectors)\n",
    "pathSum = positionVectors.reduce(lambda x,y: [x[0] + y[0], x[1] + y[1], x[2] + y[2]])\n",
    "print pathSum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
